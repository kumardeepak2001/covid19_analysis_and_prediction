{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NOTE :-  Dataset for this Project https://drive.google.com/file/d/1AI67IuvBX8YjqfIKV0i4gqaWK2eKgnYC/view?usp=drive_link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MvHCIhhYDp8a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models,layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kmxTE-crDp8b"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 128\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "gtd9-VZ7Dp8c",
        "outputId": "35ef46bc-8296-4004-bf2f-ccf7aadaf2bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6172 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        " r\"dataset\\train\",\n",
        "    shuffle=True,\n",
        "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jQQ-lnqDp8d"
      },
      "outputs": [],
      "source": [
        "#train_ds = train.skip(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SjvFpXihDp8d",
        "outputId": "b5f5ffa5-7821-47c3-d06a-2064f42b46b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1134 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_ds =  tf.keras.preprocessing.image_dataset_from_directory(\n",
        " r\"dataset\\test\",\n",
        "    shuffle=True,\n",
        "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bmj1fbKZDp8e",
        "outputId": "ee32f598-3996-450d-c858-9b9eb6a2b07d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['covid', 'normal']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_name = train_ds.class_names\n",
        "class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jGxyz8taDp8e",
        "outputId": "2023302b-8fb9-4c26-b3d8-2f2f4354a6d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2090 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "valid_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        " r\"dataset\\validation\",\n",
        "    shuffle=True,\n",
        "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ml1yKbODp8f"
      },
      "outputs": [],
      "source": [
        "#valid_ds = valid.skip(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AsZonYpQDp8g"
      },
      "outputs": [],
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Resizing(IMAGE_SIZE,IMAGE_SIZE),\n",
        "    layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2BJF66jBDp8g"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iVJsTzGSDp8g"
      },
      "outputs": [],
      "source": [
        "input_shape = (BATCH_SIZE,IMAGE_SIZE,IMAGE_SIZE,3)\n",
        "model = models.Sequential([\n",
        "    resize_and_rescale,\n",
        "    data_augmentation,\n",
        "    layers.Conv2D(32,(3,3),activation='relu',input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64,kernel_size=(3,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64,kernel_size=(3,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(128,kernel_size=(3,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(128,kernel_size=(3,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512,activation='relu'),\n",
        "    layers.Dense(128,activation='relu'),\n",
        "    layers.Dense(64,activation='relu'),\n",
        "    layers.Dense(1,activation = 'sigmoid')\n",
        "\n",
        "])\n",
        "model.build(input_shape=input_shape)\n",
        "#input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xPdFc_iuDp8h",
        "outputId": "29bd4ed9-e5ae-4cd7-e01f-332d330a5a0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (32, 128, 128, 3)         0         \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (32, 128, 128, 3)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (32, 126, 126, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (32, 63, 63, 32)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (32, 61, 61, 64)          18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (32, 30, 30, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (32, 28, 28, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (32, 14, 14, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (32, 12, 12, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (32, 6, 6, 128)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (32, 4, 4, 128)           147584    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (32, 2, 2, 128)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (32, 512)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (32, 512)                 262656    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (32, 128)                 65664     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (32, 64)                  8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (32, 1)                   65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 614,401\n",
            "Trainable params: 614,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7Hwu7Af-Dp8h"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        " optimizer = 'adam',\n",
        " loss = 'binary_crossentropy',\n",
        " metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0-yv794CDp8h",
        "outputId": "fcbbb021-d152-4afc-fb8c-b43d2135f549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "193/193 [==============================] - 123s 620ms/step - loss: 0.6503 - accuracy: 0.6035 - val_loss: 0.5472 - val_accuracy: 0.7077\n",
            "Epoch 2/10\n",
            "193/193 [==============================] - 95s 489ms/step - loss: 0.5934 - accuracy: 0.6776 - val_loss: 0.4865 - val_accuracy: 0.7632\n",
            "Epoch 3/10\n",
            "193/193 [==============================] - 95s 491ms/step - loss: 0.5359 - accuracy: 0.7218 - val_loss: 0.4453 - val_accuracy: 0.8010\n",
            "Epoch 4/10\n",
            "193/193 [==============================] - 95s 493ms/step - loss: 0.4817 - accuracy: 0.7508 - val_loss: 0.4249 - val_accuracy: 0.8024\n",
            "Epoch 5/10\n",
            "193/193 [==============================] - 99s 513ms/step - loss: 0.4533 - accuracy: 0.7775 - val_loss: 0.4250 - val_accuracy: 0.8067\n",
            "Epoch 6/10\n",
            "193/193 [==============================] - 103s 531ms/step - loss: 0.4244 - accuracy: 0.7921 - val_loss: 0.4152 - val_accuracy: 0.8014\n",
            "Epoch 7/10\n",
            "193/193 [==============================] - 98s 508ms/step - loss: 0.4117 - accuracy: 0.8054 - val_loss: 0.3743 - val_accuracy: 0.8316\n",
            "Epoch 8/10\n",
            "193/193 [==============================] - 94s 488ms/step - loss: 0.3886 - accuracy: 0.8195 - val_loss: 0.3815 - val_accuracy: 0.8431\n",
            "Epoch 9/10\n",
            "193/193 [==============================] - 102s 530ms/step - loss: 0.3706 - accuracy: 0.8343 - val_loss: 0.3761 - val_accuracy: 0.8392\n",
            "Epoch 10/10\n",
            "193/193 [==============================] - 103s 534ms/step - loss: 0.3557 - accuracy: 0.8402 - val_loss: 0.3261 - val_accuracy: 0.8584\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "   train_ds,\n",
        "   epochs = 10,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    verbose=1,\n",
        "    validation_data = valid_ds\n",
        "\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
